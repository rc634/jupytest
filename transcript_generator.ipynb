{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae64b126",
   "metadata": {},
   "source": [
    "## Load needed modules and define path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348d0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for speech to text\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edb008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pyannote/speaker-diarization',\n",
       " 'pyannote/overlapped-speech-detection',\n",
       " 'pyannote/voice-activity-detection',\n",
       " 'pyannote/speaker-segmentation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for pyannote-audio's diarisation\n",
    "import torch\n",
    "from huggingface_hub import HfApi\n",
    "available_pipelines = [p.modelId for p in HfApi().list_models(filter=\"pyannote-audio-pipeline\")]\n",
    "available_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d34af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cached_download() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyannote\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m----> 2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyannote/speaker-diarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:98\u001b[0m, in \u001b[0;36mPipeline.from_pretrained\u001b[0;34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001b[0m\n\u001b[1;32m     94\u001b[0m pipeline_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     95\u001b[0m Klass \u001b[38;5;241m=\u001b[39m get_class_by_name(\n\u001b[1;32m     96\u001b[0m     pipeline_name, default_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote.pipeline.blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mKlass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# freeze  parameters\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreeze\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:117\u001b[0m, in \u001b[0;36mSpeakerDiarization.__init__\u001b[0;34m(self, segmentation, embedding, clustering, expects_num_speakers, segmentation_batch_size, embedding_batch_size)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_segmentation \u001b[38;5;241m=\u001b[39m Inference(\n\u001b[1;32m    113\u001b[0m     model, skip_aggregation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_batch_size\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames: SlidingWindow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_segmentation\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mintrospection\u001b[38;5;241m.\u001b[39mframes\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_batch_size \u001b[38;5;241m=\u001b[39m embedding_batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    119\u001b[0m     model\u001b[38;5;241m.\u001b[39mspecifications\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_audio \u001b[38;5;241m=\u001b[39m Audio(sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39msample_rate, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_verification.py:275\u001b[0m, in \u001b[0;36mPretrainedSpeakerEmbedding\u001b[0;34m(embedding, device)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"Pretrained speaker embedding\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m>>> embeddings = get_embedding(waveforms, masks=masks)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSpeechBrainPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyannoteAudioPretrainedSpeakerEmbedding(embedding, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_verification.py:95\u001b[0m, in \u001b[0;36mSpeechBrainPretrainedSpeakerEmbedding.__init__\u001b[0;34m(self, embedding, device)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier_ \u001b[38;5;241m=\u001b[39m \u001b[43mEncoderClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCACHE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/speechbrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:331\u001b[0m, in \u001b[0;36mPretrained.from_hparams\u001b[0;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     clsname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    330\u001b[0m     savedir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pretrained_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclsname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mhash\u001b[39m(source)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 331\u001b[0m hparams_local_path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     pymodule_local_path \u001b[38;5;241m=\u001b[39m fetch(\n\u001b[1;32m    336\u001b[0m         pymodule_file, source, savedir, use_auth_token\n\u001b[1;32m    337\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/speechbrain/pretrained/fetching.py:116\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(filename, source, savedir, overwrite, save_filename, use_auth_token)\u001b[0m\n\u001b[1;32m    114\u001b[0m url \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mhf_hub_url(source, filename)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     fetched_file \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcached_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cached_download() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4196229",
   "metadata": {},
   "source": [
    "## Specify the file and desired time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3460b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"audio\" # \"xiglo\"\n",
    "audio = base + \".wav\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c5b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_START = 480.\n",
    "GLOBAL_END = 540."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60187b7",
   "metadata": {},
   "source": [
    "## Speech to text on specified time segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfa2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio.wav\r\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "audio_sr = sr.AudioFile(audio)\n",
    "!ls *wav\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143d2567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheers yeah none of it comes back out to me it's a limited company and it just says the third one is there are four of us it's a mental health trust yeah and the money just goes into pay the employees salary I don't take anything from it no could I know no sure ok so that I don't want to take it and then got someone goes all that wasn't are no woman no no no what I'm going to do is I'll basically what you said he's going to ring up 84 UK and clarify that with them so I think it's important to so first one is it's open but there's nothing going in and it's not trading or non-trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get it it's in the business it's a limited\n"
     ]
    }
   ],
   "source": [
    "with audio_sr as source:\n",
    "    audiodata = r.record(source, offset=GLOBAL_START, duration = GLOBAL_END-GLOBAL_START)\n",
    "try:\n",
    "    print(r.recognize_google(audiodata,language=\"en-GB\"))\n",
    "except Exception as e:\n",
    "    print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbafbb5",
   "metadata": {},
   "source": [
    "# DONT RUN THIS NEXT CELL!\n",
    "## this performs the diarisation on the 10 minute audio file, it takes a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d49eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7f60e45a5df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia = pipeline(audio)\n",
    "dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37efc71",
   "metadata": {},
   "source": [
    "## Print out resulting time buckets of diarisation within desired time section\n",
    "## Visualise the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5ecc56ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=480.3s stop=480.8s speaker_SPEAKER_01\n",
      "start=480.6s stop=480.8s speaker_SPEAKER_00\n",
      "start=481.1s stop=483.9s speaker_SPEAKER_01\n",
      "start=481.1s stop=481.5s speaker_SPEAKER_00\n",
      "start=484.3s stop=486.3s speaker_SPEAKER_01\n",
      "start=486.9s stop=487.3s speaker_SPEAKER_01\n",
      "start=487.5s stop=490.9s speaker_SPEAKER_01\n",
      "start=491.5s stop=492.4s speaker_SPEAKER_00\n",
      "start=491.8s stop=495.5s speaker_SPEAKER_01\n",
      "start=495.8s stop=496.7s speaker_SPEAKER_01\n",
      "start=498.5s stop=500.6s speaker_SPEAKER_00\n",
      "start=501.0s stop=501.7s speaker_SPEAKER_01\n",
      "start=502.6s stop=504.1s speaker_SPEAKER_00\n",
      "start=504.3s stop=505.2s speaker_SPEAKER_01\n",
      "start=504.4s stop=504.9s speaker_SPEAKER_00\n",
      "start=505.4s stop=506.4s speaker_SPEAKER_01\n",
      "start=506.7s stop=509.2s speaker_SPEAKER_01\n",
      "start=510.0s stop=510.5s speaker_SPEAKER_00\n",
      "start=510.1s stop=511.2s speaker_SPEAKER_01\n",
      "start=511.4s stop=518.6s speaker_SPEAKER_00\n",
      "start=519.0s stop=520.5s speaker_SPEAKER_00\n",
      "start=520.8s stop=523.1s speaker_SPEAKER_00\n",
      "start=523.7s stop=524.5s speaker_SPEAKER_00\n",
      "start=524.1s stop=525.5s speaker_SPEAKER_01\n",
      "start=525.6s stop=527.8s speaker_SPEAKER_00\n",
      "start=528.8s stop=536.6s speaker_SPEAKER_00\n",
      "start=535.0s stop=537.0s speaker_SPEAKER_01\n",
      "start=537.2s stop=538.2s speaker_SPEAKER_01\n",
      "start=538.5s stop=539.7s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "for turn, _, speaker in dia.itertracks(yield_label=True):\n",
    "    if (turn.start > GLOBAL_START and turn.start < GLOBAL_END):\n",
    "        print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e844136e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7f60e45a5df0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we visualize [0, 30] time range\n",
    "from pyannote.core import notebook, Segment\n",
    "notebook.crop = Segment(GLOBAL_START, GLOBAL_END)\n",
    "dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132e651",
   "metadata": {},
   "source": [
    "## Speech recognition on the above diarisation time bins and output with labelled speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2bfe90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[1;32m      4\u001b[0m audio_sr \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mAudioFile(audio)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio_sr = sr.AudioFile(audio)\n",
    "!ls *wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "791f84c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : none of it comes back out to me it's a\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : and it just stays there\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_01 : there were four of us it's a mental\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : yeah and the manor just goes in to pay the employees\n",
      "\n",
      "SPEAKER_01 : anything\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_00 : no no sure\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_01 : take it and then go and someone goes all that\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : no\n",
      "\n",
      "SPEAKER_00 : no no no what I'm going to do is I'll basically what you said it's going to ring up 8 for UK and clarify that with them so I think it's in\n",
      "\n",
      "SPEAKER_00 : first one\n",
      "\n",
      "SPEAKER_00 : is it open but there's no\n",
      "\n",
      "SPEAKER_00 : ???\n",
      "\n",
      "SPEAKER_01 : and now it's not\n",
      "\n",
      "SPEAKER_00 : oh no not trading\n",
      "\n",
      "SPEAKER_00 : the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get those\n",
      "\n",
      "SPEAKER_01 : actually just get\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n",
      "SPEAKER_01 : ???\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for turn, _, speaker in dia.itertracks(yield_label=True):\n",
    "    start_time = turn.start\n",
    "    end_time = turn.end\n",
    "    if (turn.start > GLOBAL_START and turn.start < GLOBAL_END):\n",
    "        with audio_sr as source:\n",
    "            audiodata = r.record(source, offset=start_time-0.1, duration = end_time-start_time+0.1)\n",
    "        try:\n",
    "            words = r.recognize_google(audiodata,language=\"en-GB\")\n",
    "            #print(f\"*------------------------START---------t={turn.start:.1f}s--------*\")\n",
    "            print(f\"{speaker} : {words}\")\n",
    "            print(\"\")\n",
    "            #print(f\"*-------------------------END----------t={turn.end:.1f}s--------*\")\n",
    "        except Exception as e:\n",
    "            print(f\"{speaker} : ???\")\n",
    "            print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c72290",
   "metadata": {},
   "source": [
    "##  Speech to text on specified time segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f336585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheers yeah none of it comes back out to me it's a limited company and it just says the third one is there are four of us it's a mental health trust yeah and the money just goes into pay the employees salary I don't take anything from it no could I know no sure ok so that I don't want to take it and then got someone goes all that wasn't are no woman no no no what I'm going to do is I'll basically what you said he's going to ring up 84 UK and clarify that with them so I think it's important to so first one is it's open but there's nothing going in and it's not trading or non-trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get it it's in the business it's a limited\n"
     ]
    }
   ],
   "source": [
    "with audio_sr as source:\n",
    "    audiodata = r.record(source, offset=GLOBAL_START, duration = GLOBAL_END-GLOBAL_START)\n",
    "try:\n",
    "    print(r.recognize_google(audiodata,language=\"en-GB\"))\n",
    "except Exception as e:\n",
    "    print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f74b7",
   "metadata": {},
   "source": [
    "## My attempt at stitching audio pieces together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968b2f1",
   "metadata": {},
   "source": [
    "##### idea here is that sometimes continuous speach by one speaker is broken into multiple chunks here, one long chunk is better for speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "488f3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=477.4s stop=480.1s speaker_SPEAKER_01\n",
      "start=480.3s stop=480.8s speaker_SPEAKER_01\n",
      "start=480.6s stop=480.8s speaker_SPEAKER_00\n",
      "start=481.1s stop=483.9s speaker_SPEAKER_01\n",
      "start=481.1s stop=481.5s speaker_SPEAKER_00\n",
      "start=484.3s stop=486.3s speaker_SPEAKER_01\n",
      "start=486.9s stop=487.3s speaker_SPEAKER_01\n",
      "start=487.5s stop=490.9s speaker_SPEAKER_01\n",
      "start=491.5s stop=492.4s speaker_SPEAKER_00\n",
      "start=491.8s stop=495.5s speaker_SPEAKER_01\n",
      "start=495.8s stop=496.7s speaker_SPEAKER_01\n",
      "start=498.5s stop=500.6s speaker_SPEAKER_00\n",
      "start=501.0s stop=501.7s speaker_SPEAKER_01\n",
      "start=502.6s stop=504.1s speaker_SPEAKER_00\n",
      "start=504.3s stop=505.2s speaker_SPEAKER_01\n",
      "start=504.4s stop=504.9s speaker_SPEAKER_00\n",
      "start=505.4s stop=506.4s speaker_SPEAKER_01\n",
      "start=506.7s stop=509.2s speaker_SPEAKER_01\n",
      "start=510.0s stop=510.5s speaker_SPEAKER_00\n",
      "start=510.1s stop=511.2s speaker_SPEAKER_01\n",
      "start=511.4s stop=518.6s speaker_SPEAKER_00\n",
      "start=519.0s stop=520.5s speaker_SPEAKER_00\n",
      "start=520.8s stop=523.1s speaker_SPEAKER_00\n",
      "start=523.7s stop=524.5s speaker_SPEAKER_00\n",
      "start=524.1s stop=525.5s speaker_SPEAKER_01\n",
      "start=525.6s stop=527.8s speaker_SPEAKER_00\n",
      "start=528.8s stop=536.6s speaker_SPEAKER_00\n",
      "start=535.0s stop=537.0s speaker_SPEAKER_01\n",
      "start=537.2s stop=538.2s speaker_SPEAKER_01\n",
      "start=538.5s stop=539.7s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "speech_fragments = []\n",
    "for turn, track, speaker in dia.itertracks(yield_label=True):\n",
    "    if (turn.end > GLOBAL_START and turn.start < GLOBAL_END):\n",
    "        speech_fragments += [[speaker,turn.start,turn.end,\"unique\"]]\n",
    "        print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "#for i in range(len(speech_fragments)): print(speech_fragments[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "68442360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPEAKER_01', 477.43218750000005, 480.8240625, 'unique']\n",
      "['SPEAKER_01', 477.43218750000005, 480.8240625, 'repeat']\n",
      "['SPEAKER_00', 480.62156250000004, 480.80718750000005, 'unique']\n",
      "['SPEAKER_01', 481.07718750000004, 483.9121875, 'unique']\n",
      "['SPEAKER_00', 481.14468750000003, 481.49906250000004, 'unique']\n",
      "['SPEAKER_01', 484.3003125, 490.89843750000006, 'unique']\n",
      "['SPEAKER_01', 484.3003125, 490.89843750000006, 'repeat']\n",
      "['SPEAKER_01', 486.8990625, 490.89843750000006, 'repeat']\n",
      "['SPEAKER_00', 491.5396875, 492.36656250000004, 'unique']\n",
      "['SPEAKER_01', 491.8265625, 496.7371875, 'unique']\n",
      "['SPEAKER_01', 491.8265625, 496.7371875, 'repeat']\n",
      "['SPEAKER_00', 498.5090625, 500.63531250000005, 'unique']\n",
      "['SPEAKER_01', 500.9559375, 501.6984375, 'unique']\n",
      "['SPEAKER_00', 502.64343750000006, 504.0946875, 'unique']\n",
      "['SPEAKER_01', 504.33093750000006, 505.15781250000003, 'unique']\n",
      "['SPEAKER_00', 504.38156250000003, 504.9046875, 'unique']\n",
      "['SPEAKER_01', 505.3603125, 509.17406250000005, 'unique']\n",
      "['SPEAKER_01', 505.3603125, 509.17406250000005, 'repeat']\n",
      "['SPEAKER_00', 509.95031250000005, 510.5240625, 'unique']\n",
      "['SPEAKER_01', 510.08531250000004, 511.18218750000005, 'unique']\n",
      "['SPEAKER_00', 511.4353125, 524.5134375, 'unique']\n",
      "['SPEAKER_00', 511.4353125, 524.5134375, 'repeat']\n",
      "['SPEAKER_00', 519.0290625, 524.5134375, 'repeat']\n",
      "['SPEAKER_00', 520.7671875000001, 524.5134375, 'repeat']\n",
      "['SPEAKER_01', 524.0578125000001, 525.5428125000001, 'unique']\n",
      "['SPEAKER_00', 525.6440625, 536.5790625000001, 'unique']\n",
      "['SPEAKER_00', 525.6440625, 536.5790625000001, 'repeat']\n",
      "['SPEAKER_01', 534.9759375, 539.7009375, 'unique']\n",
      "['SPEAKER_01', 534.9759375, 539.7009375, 'repeat']\n",
      "['SPEAKER_01', 537.1528125, 539.7009375, 'repeat']\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(speech_fragments)-1)): # the reverse is important as we want to pull the latest finish time to the first start time\n",
    "    frag = speech_fragments[i]\n",
    "    nextfrag = speech_fragments[i+1]\n",
    "    if frag[0]==nextfrag[0]:\n",
    "        nextfrag[1] = frag[1]\n",
    "        frag[2]=nextfrag[2]\n",
    "        nextfrag[3] = \"repeat\"\n",
    "    \n",
    "for frag in speech_fragments: print(frag)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba396e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=477.4s stop=480.8s speaker_SPEAKER_01\n",
      "start=480.6s stop=480.8s speaker_SPEAKER_00\n",
      "start=481.1s stop=483.9s speaker_SPEAKER_01\n",
      "start=481.1s stop=481.5s speaker_SPEAKER_00\n",
      "start=484.3s stop=490.9s speaker_SPEAKER_01\n",
      "start=491.5s stop=492.4s speaker_SPEAKER_00\n",
      "start=491.8s stop=496.7s speaker_SPEAKER_01\n",
      "start=498.5s stop=500.6s speaker_SPEAKER_00\n",
      "start=501.0s stop=501.7s speaker_SPEAKER_01\n",
      "start=502.6s stop=504.1s speaker_SPEAKER_00\n",
      "start=504.3s stop=505.2s speaker_SPEAKER_01\n",
      "start=504.4s stop=504.9s speaker_SPEAKER_00\n",
      "start=505.4s stop=509.2s speaker_SPEAKER_01\n",
      "start=510.0s stop=510.5s speaker_SPEAKER_00\n",
      "start=510.1s stop=511.2s speaker_SPEAKER_01\n",
      "start=511.4s stop=524.5s speaker_SPEAKER_00\n",
      "start=524.1s stop=525.5s speaker_SPEAKER_01\n",
      "start=525.6s stop=536.6s speaker_SPEAKER_00\n",
      "start=535.0s stop=539.7s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "fixed_speech = []      \n",
    "for frag in speech_fragments:\n",
    "    if (frag[3]==\"unique\"):\n",
    "        fixed_speech += [frag]\n",
    "        \n",
    "for frag in fixed_speech: print(f\"start={frag[1]:.1f}s stop={frag[2]:.1f}s speaker_{frag[0]}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5e9c409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*------------------------START---------t=477.4s--------*\n",
      "SPEAKER_01 : that takes cash in as people stay in the lodge\n",
      "*-------------------------END----------t=480.8s--------*\n",
      "*------------------------START---------t=480.6s--------*\n",
      "??? \n",
      "*-------------------------END----------t=480.8s--------*\n",
      "*------------------------START---------t=481.1s--------*\n",
      "SPEAKER_01 : none of it comes back out to me it's a\n",
      "*-------------------------END----------t=483.9s--------*\n",
      "*------------------------START---------t=481.1s--------*\n",
      "??? \n",
      "*-------------------------END----------t=481.5s--------*\n",
      "*------------------------START---------t=484.3s--------*\n",
      "SPEAKER_01 : and it just says the third one is there for four of us it's a mental\n",
      "*-------------------------END----------t=490.9s--------*\n",
      "*------------------------START---------t=491.5s--------*\n",
      "??? \n",
      "*-------------------------END----------t=492.4s--------*\n",
      "*------------------------START---------t=491.8s--------*\n",
      "SPEAKER_01 : yeah and the manor just goes in to pay the employees salary I don't take\n",
      "*-------------------------END----------t=496.7s--------*\n",
      "*------------------------START---------t=498.5s--------*\n",
      "??? \n",
      "*-------------------------END----------t=500.6s--------*\n",
      "*------------------------START---------t=501.0s--------*\n",
      "??? \n",
      "*-------------------------END----------t=501.7s--------*\n",
      "*------------------------START---------t=502.6s--------*\n",
      "SPEAKER_00 : no no sure\n",
      "*-------------------------END----------t=504.1s--------*\n",
      "*------------------------START---------t=504.3s--------*\n",
      "??? \n",
      "*-------------------------END----------t=505.2s--------*\n",
      "*------------------------START---------t=504.4s--------*\n",
      "??? \n",
      "*-------------------------END----------t=504.9s--------*\n",
      "*------------------------START---------t=505.4s--------*\n",
      "SPEAKER_01 : is that I don't want to take it and then go and someone goes\n",
      "*-------------------------END----------t=509.2s--------*\n",
      "*------------------------START---------t=510.0s--------*\n",
      "??? \n",
      "*-------------------------END----------t=510.5s--------*\n",
      "*------------------------START---------t=510.1s--------*\n",
      "SPEAKER_01 : no\n",
      "*-------------------------END----------t=511.2s--------*\n",
      "*------------------------START---------t=511.4s--------*\n",
      "SPEAKER_00 : no no no what I'm going to do is I'll basically what you said it's going to ring up 8 for UK and clarify that with them so I think it's important to so first one is it open but there's nothing going in\n",
      "*-------------------------END----------t=524.5s--------*\n",
      "*------------------------START---------t=524.1s--------*\n",
      "SPEAKER_01 : and now it's not\n",
      "*-------------------------END----------t=525.5s--------*\n",
      "*------------------------START---------t=525.6s--------*\n",
      "SPEAKER_00 : oh well not trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get those\n",
      "*-------------------------END----------t=536.6s--------*\n",
      "*------------------------START---------t=535.0s--------*\n",
      "SPEAKER_01 : actually just get so it's in the business it's\n",
      "*-------------------------END----------t=539.7s--------*\n"
     ]
    }
   ],
   "source": [
    "for frag in fixed_speech:\n",
    "    with audio_sr as source:\n",
    "            audiodata = r.record(source, offset=frag[1]-0.1, duration = frag[2]-frag[1]+0.1)\n",
    "    try:\n",
    "        words = r.recognize_google(audiodata,language=\"en-GB\")\n",
    "        print(f\"*------------------------START---------t={frag[1]:.1f}s--------*\")\n",
    "        print(f\"{frag[0]} : {words}\")\n",
    "        print(f\"*-------------------------END----------t={frag[2]:.1f}s--------*\")\n",
    "    except Exception as e:\n",
    "        print(f\"*------------------------START---------t={frag[1]:.1f}s--------*\")\n",
    "        print(f\"??? \")\n",
    "        print(f\"*-------------------------END----------t={frag[2]:.1f}s--------*\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd7bc7",
   "metadata": {},
   "source": [
    "## hand transcribed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed525fd6",
   "metadata": {},
   "source": [
    "SPEAKER_00 : yeah \n",
    "\n",
    "SPEAKER_01 : but none of it comes back out to me it's a limited company and it just says there the third one is umm there are four four of us it's a mental health trust \n",
    "\n",
    "SPEAKER_00 : yeah \n",
    "\n",
    "SPEAKER_01 : and the money just goes in to pay the employees salary I don't take anything from it \n",
    "\n",
    "SPEAKER_00 : errrr\n",
    "\n",
    "SPEAKER_01 : and nor could I \n",
    "\n",
    "SPEAKER_00 : no no sure erm ok \n",
    "\n",
    "SPEAKER_01 : it's that I don't want to take it and then gum(?) someone goes ah well that wasn't our\n",
    "\n",
    "SPEAKER_00 : no \n",
    "\n",
    "??? \n",
    "\n",
    "SPEAKER_00 : no no no what I'm going to do is I'll based on what you said is i'm going to ring up april(?) UK and clarify that with them cos I think it's important to so\n",
    "\n",
    "SPEAKER_01 : yea\n",
    "\n",
    "SPEAKER_00 : first one is it's open but there's nothing going in and \n",
    "\n",
    "SPEAKER_01 : or out it's not trading \n",
    "\n",
    "SPEAKER_00 : or out not trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just \n",
    "\n",
    "SPEAKER_01 : well yea it sits in the business it sits in the business it's a limited company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37827b21",
   "metadata": {},
   "source": [
    "## plain speech to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382b9df",
   "metadata": {},
   "source": [
    "cheers yeah none of it comes back out to me it's a limited company and it just says the third one is there are four of us it's a mental health trust yeah and the money just goes into pay the employees salary I don't take anything from it no could I know no sure ok so that I don't want to take it and then got someone goes all that wasn't are no woman no no no what I'm going to do is I'll basically what you said he's going to ring up 84 UK and clarify that with them so I think it's important to so first one is it's open but there's nothing going in and it's not trading or non-trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get it it's in the business it's a limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691f176",
   "metadata": {},
   "source": [
    "## automatic transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "311b8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_01 : that takes cash in as people stay in the lodge\n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : none of it comes back out to me it's a\n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : and it just says the third one is there for four of us it's a mental\n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : yeah and the manor just goes in to pay the employees salary I don't take\n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : ??? \n",
      "\n",
      "SPEAKER_00 : no no sure\n",
      "\n",
      "SPEAKER_01 : ??? \n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : is that I don't want to take it and then go and someone goes\n",
      "\n",
      "SPEAKER_00 : ??? \n",
      "\n",
      "SPEAKER_01 : no\n",
      "\n",
      "SPEAKER_00 : no no no what I'm going to do is I'll basically what you said it's going to ring up 8 for UK and clarify that with them so I think it's important to so first one is it open but there's nothing going in\n",
      "\n",
      "SPEAKER_01 : and now it's not\n",
      "\n",
      "SPEAKER_00 : oh well not trading ok the second one is cash in but it goes automatically so that's holiday lettings and it automatically just get those\n",
      "\n",
      "SPEAKER_01 : actually just get so it's in the business it's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for frag in fixed_speech:\n",
    "    with audio_sr as source:\n",
    "            audiodata = r.record(source, offset=frag[1]-0.1, duration = frag[2]-frag[1]+0.1)\n",
    "    try:\n",
    "        words = r.recognize_google(audiodata,language=\"en-GB\")\n",
    "        print(f\"{frag[0]} : {words}\")\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"{frag[0]} : ??? \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c572f87",
   "metadata": {},
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3b870",
   "metadata": {},
   "source": [
    "#### -> try ignoring bins of too small width or merge them with bigger bins\n",
    "#### -> try messing with yield_label=True in the dia.intertracks\n",
    "#### -> look into the _ argument too?\n",
    "#### -> try extending bins to regions of no speech, maybe improves accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5592c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8946305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff842db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
